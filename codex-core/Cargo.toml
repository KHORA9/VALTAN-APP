[package]
name = "codex-core"
version = "0.1.0"
edition = "2021"
description = "Core library for Codex Vault Next-Gen - Offline AI-powered knowledge repository"
license = "MIT"
repository = "https://github.com/hanatra-limited/codex-vault"
keywords = ["ai", "knowledge", "offline", "search", "rag"]
categories = ["database", "text-processing", "science"]

[lib]
name = "codex_core"
crate-type = ["cdylib", "rlib"]

[dependencies]
# Database
sqlx = { version = "0.7", features = ["runtime-tokio-rustls", "sqlite", "chrono", "uuid", "migrate"] }
sqlite = "0.36"

# Async runtime
tokio = { version = "1.0", features = ["full"] }
futures = "0.3"

# Serialization
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"
bincode = "1.3"

# Error handling
thiserror = "1.0"
anyhow = "1.0"

# Logging
tracing = "0.1"
tracing-subscriber = { version = "0.3", features = ["env-filter"] }

# Utilities
uuid = { version = "1.0", features = ["v4", "serde"] }
chrono = { version = "0.4", features = ["serde"] }
regex = "1.0"
once_cell = "1.19"

# AI/ML dependencies
candle-core = "0.6"
candle-nn = "0.6"
candle-transformers = "0.6"
tokenizers = "0.19"
hf-hub = "0.3"

# Text processing
unicode-normalization = "0.1"
unicode-segmentation = "1.10"

# Compression
flate2 = "1.0"
lz4 = "1.24"

# Vector operations
ndarray = "0.15"
approx = "0.5"

# HTTP client for model downloads
reqwest = { version = "0.12", features = ["json", "stream"] }

# Configuration
config = "0.14"
directories = "5.0"
toml = "0.8"

# Tauri integration
tauri = { version = "1.0", features = ["api-all"] }

[dev-dependencies]
tempfile = "3.8"
proptest = "1.0"
criterion = { version = "0.5", features = ["html_reports"] }

[features]
default = ["sqlite"]
sqlite = []
ai-gpu = ["candle-core/cuda"]
ai-metal = ["candle-core/metal"]

[[bench]]
name = "ai_inference"
harness = false

[[bench]]
name = "search_performance"
harness = false

[profile.release]
opt-level = 3
lto = true
codegen-units = 1
panic = "abort"

[profile.dev]
opt-level = 0
debug = true
split-debuginfo = "unpacked"